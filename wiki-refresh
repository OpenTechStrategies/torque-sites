#!/bin/bash

# Load all the 100&Change proposals into a wiki.
#
# Copyright (C) 2017  Open Tech Strategies, LLC
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
# 
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

##########################################################################
#                                                                        #
#   NOTE: This code is highly specific to the particular filenames and   #
#   working environment used by Open Tech Strategies on a project for    #
#   the MacArthur Foundation.  For our own convenience, we have left     #
#   those assumptions in place.  That means this script won't work if    #
#   someone else tries to run it; we publish it just as an example.      #
#   It is open source software, so please modify it to suit your needs.  #
#                                                                        #
##########################################################################

MACFOUND_DIR=`dirname "${0}"`
SOURCES_ROOT="${MACFOUND_DIR}/.."
DATA_DIR="${1}"


function check_for_bin {
	command -v $1 >/dev/null 2>&1 || { echo >&2 "$1 required but it's not available.  Aborting."; exit 1; }
}


if [ "${DATA_DIR}" = "" ]; then
    [ -d "${OTSDIR}/clients/macfound/eval-system/data" ] && DATA_DIR="${OTSDIR}/clients/macfound/eval-system/data"
fi

if [ "${DATA_DIR}" = "" ]; then
  echo "ERROR: DATA_DIRECTORY argument required."
  echo ""
  echo "Usage: '${0} DATA_DIRECTORY'"
  echo ""
  echo "(DATA_DIRECTORY is where all the .csv files are.)"
  echo ""
  exit 1
fi

# Make sure we have csvkit by checking version on csvgrep.
# If we don't have it, one way to get it would be:
#
#   $ git clone https://github.com/wireservice/csvkit.git
#   $ cd csvkit
#   $ sudo python3 setup.py install --prefix=/usr/local
check_for_bin csvgrep
csvgrep --version 2&>/dev/null || { echo "csvkit needs to be a recent version. Please upgrade to version 1.0.2+"; exit 1; }

# Make sure we have csv2wiki.
CSV2WIKI="${SOURCES_ROOT}/csv2wiki/csv2wiki"
if [ ! -x ${CSV2WIKI} ]; then
  CSV2WIKI=${OTSDIR}/clients/macfound/eval-system/csv2wiki/csv2wiki
fi
if [ ! -x ${CSV2WIKI} ]; then
  CSV2WIKI=${OTSDIR}/clients/macfound/eval-system/r/csv2wiki/csv2wiki
fi
if [ ! -x ${CSV2WIKI} ]; then
  CSV2WIKI=${OTSDIR}/csv2wiki/csv2wiki
fi
if [ ! -x ${CSV2WIKI} ]; then
  CSV2WIKI=${OTSDIR}/r/csv2wiki/csv2wiki
fi
if [ ! -x ${CSV2WIKI} ]; then
  # Okay, let's get medieval on the situation.
  (cd "${SOURCES_ROOT}"; \
   git clone https://github.com/OpenTechStrategies/csv2wiki.git)
  CSV2WIKI="${SOURCES_ROOT}/csv2wiki/csv2wiki"
fi
if [ ! -x ${CSV2WIKI} ]; then
  echo "ERROR: Unable to find or clone 'csv2wiki'."
  exit 1
fi
# Test that csv2wiki actually works.
if ${CSV2WIKI} --help > /dev/null; then
  echo "Great, it works." > /dev/null
else
  echo "ERROR: Problem running ${CSV2WIKI}."
  echo ""
  echo "Most likely you need to install the 'mwclient' and 'unidecode'"
  echo "Python modules.  Do 'pip install mwclient', and same for"
  echo "'bs4' and 'unidecode', and try running this script again."
  exit 1
fi

# csv2wiki needs a run-time config file.
CSV2WIKI_CONFIG="${MACFOUND_DIR}"/csv2wiki-config
if [ ! -f "${CSV2WIKI_CONFIG}" ]; then
  echo "ERROR: No csv2wiki-config file found."
  echo ""
  echo "Try doing 'cp csv2wiki-config.tmpl csv2wiki-config' and"
  echo "then editing csv2wiki-config as needed."
  echo ""
  exit 1
fi

MASTER_CSV="${DATA_DIR}/100andchangeExport-all-judges.csv"

# We've extracted the excluded Review Numbers from Exclusions.xlsx.
# They're saved elsewhere, but for the record, here's how it was done,
# using the 'in2csv' program from csvkit:
# 
#   $ in2csv ${DATA_DIR}/Exclusions.xlsx > ${DATA_DIR}/Exclusions.csv
#   .../lib/python2.7/site-packages/agate/utils.py:275: UnnamedColumnWarning: Column 0 has no name. Using "a".
#   .../lib/python2.7/site-packages/agate/utils.py:275: UnnamedColumnWarning: Column 1 has no name. Using "b".
#   .../lib/python2.7/site-packages/agate/utils.py:275: UnnamedColumnWarning: Column 2 has no name. Using "c".
#   .../lib/python2.7/site-packages/agate/utils.py:275: UnnamedColumnWarning: Column 3 has no name. Using "d".
#   .../lib/python2.7/site-packages/agate/utils.py:275: UnnamedColumnWarning: Column 4 has no name. Using "e".
#   .../lib/python2.7/site-packages/agate/utils.py:275: UnnamedColumnWarning: Column 5 has no name. Using "f".
# 
#   $ csvcut -n ${DATA_DIR}/Exclusions.csv
#   1: a
#   2: b
#   3: c
#   4: d
#   5: e
#   6: f
# 
#   $ csvlook ~/private/work/ots/clients/macfound/eval-system/data/Exclusions.csv
#   ...see from output that column "a" has the Review Numbers we want...
# 
#   $ csvcut -c a ~/private/work/ots/clients/macfound/eval-system/data/Exclusions.csv \
#           | grep -E "[0-9]+" > ${DATA_DIR}/excluded-review-numbers.txt
# 
#   $ cat ${DATA_DIR}/excluded-review-numbers.txt
#   6587
#   6226
#   72
#   671
#   1095
#   1723
#   2681
#   4046
#   5861
#   6381
#   6728
#   6882
#   5653
#   3030
#   5073
# 
#   $ svn add ${DATA_DIR}/excluded-review-numbers.txt
# 
#   $ svn ci -m "Save excluded Review Numbers (based on Exclusions.xlsx)." \
#                     ${DATA_DIR}/excluded-review-numbers.txt
# 
#   $ 

RAW_CSV="100andchangeExport-all-judges.csv"

SANITIZER="${MACFOUND_DIR}"/fix-csv

# First we sanitize, then we filter, then we join.  MacFound probably
# wants the Stage 3 spreadsheet as a deliverable, but in principle
# we could deliver any of them.  (There is some question as to whether
# they would want filtering to happen before joining or vice versa;
# we can ask -- it wouldn't be too hard to change the order.)
STAGE_1_PREFIX="sanitized-"
STAGE_2_PREFIX="filtered-"

STAGE_1_CSV="${STAGE_1_PREFIX}${RAW_CSV}"
STAGE_2_CSV="${STAGE_2_PREFIX}${RAW_CSV}"

# Sanitize the updated spreadsheet.
#
# Use --pare to convert only 1% of the entries, to save time while testing. 
echo "Stage 1: Sanitizing..."
${SANITIZER} --pare=100 --reclassifications="${DATA_DIR}/geo-and-topic-revisions-Reclassify-themes-ALL-complete-(merged-assignment-docs).csv" \
             "${DATA_DIR}/${RAW_CSV}" \
             "${DATA_DIR}/${STAGE_1_CSV}"
if [ $? -ne 0 ]; then
		echo Sanitization failure!
		exit 1
fi
echo "Done with Stage 1 (sanitizing)."
echo ""

# Filter out excluded Review Numbers.
echo "Stage 2: Filtering excluded Review Numbers..."
csvgrep -c 15 -f "${DATA_DIR}"/excluded-review-numbers.txt -i \
        "${DATA_DIR}"/${STAGE_1_CSV} > "${DATA_DIR}"/"${STAGE_2_CSV}"
echo "Done with Stage 2 (filtering excluded Review Numbers)."
echo ""

echo "Creating wiki..."
${CSV2WIKI} --cat-sort=alpha -c ${CSV2WIKI_CONFIG} "${DATA_DIR}/${STAGE_2_CSV}"
echo "Done creating wiki."
echo ""

# We need to upload Team MOUs and Team Descriptions as attachments,
# for those proposals that have one or the other or both available.
#
# Make sure that the file "100andchange_team_MoUs.zip" exists in
# ${DATA_DIR}, i.e., the Dropbox "100andchange_team_MoUs" folder
# downloaded as a .zip file.  NOTE: there's separate file in Dropbox
# named "100andchange_team_MoUs-20170509.zip", and it is *not* the one
# we want.  We want the *folder* "100andchange_team_MoUs", downloaded
# such that it becomes a .zip file only locally.  Got that?  Good.
#
# In ${DATA_DIR}/team-MOUs-and-descriptions/ there are two files
# already prepared:
#
#   - memoranda-of-understanding.txt
#   - team-descriptions.txt
#
# The first was produced via manual inspection (every file that had
# "mou" case-insensitively in its name in such a way that it it means
# "memorandum of understanding" and isn't just part of the org's real
# name).  The second was produced relative to the first:
#
#   $ /bin/ls -1 | grep -v memoranda-of-understanding.txt |           \
#       while read name; do                                           \
#         if ! grep -q "${name}" memoranda-of-understanding.txt; then \
#           echo "${name}";                                           \
#         fi;                                                         \
#       done
#
# We just unpack the MOU and description files directly into the same
# directory (their names are never going to conflict with the two
# files above) and upload as appropriate, based on review number,
# which will always be the front of the file name followed by two
# underscores, matching this regexp: "^[0-9]+__"
#
# TODO: Except, wait, we don't actually have any upload code yet!  We
# don't even know those APIs!  So comment this part out for now:
#
#   SAVED_CWD=`pwd`
#   cd ${DATA_DIR}/team-MOUs-and-descriptions
#   unzip -l ../100andchange_team_MoUs.zip
#   cd ${SAVED_CWD}
