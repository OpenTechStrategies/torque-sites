#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
# Perform some one-time fixes to the MacArthur Foundation 100&Change CSV file
#
# This is necessary because not everything can be addressed with the
# 'sanitize' script.  The 'sanitize' script isn't aware of CSV rows or
# columns; it just treats the whole CSV file as a normal text file.
# But for, e.g., fixing the YouTube links (see features.org for more),
# we really need a one-time transformation that knows what cell it's
# operating on.
#
# Copyright (C) 2017, 2019, 2020 Open Tech Strategies, LLC
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published
# by the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <http://www.gnu.org/licenses/>.

##########################################################################
#                                                                        #
#   NOTE: This code is highly specific to the needs of the MacArthur     #
#   Foundation and is unlikely to be correct for your CSV.  It is        #
#   open source software, so please modify it to suit your needs.        #
#                                                                        #
##########################################################################

__doc__ = """\
Compose all of the MacArthur Foundation 2019 Proposal CSV files.

Usage:

  $ compose-csvs \\
       --proposals-csv=PROPOSALS_CSV \\
       --admin-review-csv=ADMIN_REVIEW_CSV \\
       --judge-evaluation-csv=JUDGE_EVALUATION_CSV \\
       --wisehead-evaluation-csv=WISEHEAD_CSV \\
       --regionconfig-csv=REGIONCONFIG_CSV \\
       --toc-dir=TOC_DIR \\
       --sdgconfig-csv=SDGCONFIG_CSV \\
       --attachments-dir=ATTACHMENTS_DIR \\
       --correction-file=COORECTION_FILE \\
       --tdc-config-dir=TDC_CONFIG_DIR

Command-line options:
  --proposals-csv FILE            FILE is a csv FILE representing the bulk
                                  of the proposal information

  --admin-review-csv FILE         FILE is a csv FILE representing which applications
                                  in PROPOSALS_CSV should be included

  --judge-evaluation-csv FILE     FILE is a csv FILE with a many to one relationshp
                                  between judges and the proposals they evaluated,
                                  with the extra data being their evaluation

  --pare N                        Reduce the nuber of tiems to 1/N rows, for quick
                                  testing and development

  --wisehead-evaluation-csv FILE  FILE is a csv FILE with a many to one relationship
                                  between wisehead judges and the proposals they
                                  evaluated, like the judge-evaluation-csv

  --regionconfig-csv FILE         FILE is a csv of country/subregion/region
                                  configurations, that when provided, allows a detailed
                                  geographic TOC to be created

  --correction-file FILE          FILE is a csv of corrections to the main data.  The header
                                  must match the header of the original proposals file, and any
                                  one of the columns must contain the review number.  Then
                                  the data from the correction file will override the
                                  source data for output.  There can be multiple correction
                                  files, and each one overwrites the previous.

  --ots-metadata FILE             FILE is a csv of MetaData created by OTS to use when creating
                                  the final spreadsheet.  Each row defines a given override attribute
                                  for a given review number, and what value should go there.
                                  This spreadsheet grows as the ETL pipeline one-off needs grow.

  --toc-dir DIR                   DIR is the directory where extra TOCs will be placed for loading
                                  up to the torque wiki with csv2wiki.  If not included, TOCs won't
                                  be generated.

  --sdgconfig-csv FILE            FILE is a csv of sdg configurations, that when provided
                                  will be checked against in the SDG column for validation
                                  and separation into a list.

  --attachments-dir DIR           DIR is a directory for compose-csvs to look in for what attachments
                                  will be uploaded to the torque wiki.  It needs to have subdirectories
                                  by proposal number.

  --tdc-config-dir DIR            DIR is the location for files that are the base configuration files
                                  needed by TorqueDataConnect, and can be optionally, manually, put on
                                  the torque wiki.  We don't autmoatically do that because we want to
                                  overwrite the configuration out there.
"""

import csv
import getopt
import re
import io
import sys
import warnings
import string
import os
import json
import pickle
from bs4 import BeautifulSoup

def collapse_replace(string, old, new):
    "Return STRING, with OLD repeatedly replaced by NEW until no more OLD."
    while string.find(old) != -1: 
        string = string.replace(old, new)
    return string

def weaken_the_strong(html):
    """Strip any meaningless <strong>...</strong> tags from HTML.
    HTML is a Unicode string; the return value is either HTML or a new
    Unicode string based on HTML.

    If <strong> tags cover everything in HTML, remove the tags.  But if
    <strong> tags are used only sometimes, maybe they're meaningful, so
    leave them.  Basically, we want to make strength great again."""
    # If there's no strength here, move on.
    if not "<strong>" in html:
        return html
    
    # Remove the stuff inside strong tags
    soup = BeautifulSoup(html, "html.parser")
    while "<strong>" in str(soup):
        soup.strong.extract()

    # Check whether the non-bold stuff is more than just tags and
    # punctuation.  If not, all the important stuff was bold, so strip
    # bold and return.
    if re.sub(r"\W", "", soup.get_text()) == "":
        return re.sub("</?strong>", "", html)

    # OTOH, if the non-bold stuff contained letters or numbers, maybe
    # there's real content there, which means the html was a mix of
    # bold and non-bold text.  Better to leave it alone.
    return html

def form_well(html):
    """Return a well-formed version of HTML with dangling tags closed.
    Some of the input includes tables that cut off without closing
    tags; some entries leave <td> tags open too."""
    # Parse html and suppress warnings about urls in the text
    warnings.filterwarnings("ignore",
                            category=UserWarning, module='bs4')
    soup = BeautifulSoup(html, "html.parser")

    # Return well-formed html as a soup object
    return soup

# Used in converting "<foo>&nbsp;<bar>" and "</foo>&nbsp;<bar>"
# to "<foo> <bar>" and "</foo> <bar>" respectively.  (Those particular
# instances of "&nbsp;" in the data are not very convincing, and they
# create noise when we're looking for unnecessary escaping elsewhere.)
intertag_nbsp_re = re.compile('(?m)(</?[a-z]+>)&nbsp;(<[a-z]+>)')

# Matches Unicode 8226 (U+2022) at the beginning of a line,
# which is something that applicants do in a lot of fields.
bullets_re = re.compile("^â€¢", re.MULTILINE)

def fix_cell(cell):
    """Return a cleaned up version of the CELL that will work well
    with mediawiki, mainly through text subsitution."""
    # A straight-up HTML-unescaping might be the right thing
    # (i.e., cell = html_parser.unescape(cell) below)
    # in the long run, but for now, let's do the same limited
    # set of unescapings the original 'sanitize' script did:
    cell = cell.replace('&amp;', '&')
    cell = cell.replace('&lt;', '<')
    cell = cell.replace('&gt;', '>')
    # The rest should be recursively collapsing replacements:
    cell = collapse_replace(cell, '\t', ' ')
    cell = collapse_replace(cell, '&nbsp;&nbsp;', '&nbsp;')
    cell = collapse_replace(cell, '&nbsp; ', ' ')
    cell = collapse_replace(cell, ' &nbsp;', ' ')
    cell = collapse_replace(cell, '&nbsp;</', '</')
    cell = collapse_replace(cell, '\\"', '"')
    cell = re.sub(intertag_nbsp_re, '\\1 \\2', cell)

    soup = form_well(cell)
    cell = weaken_the_strong(str(soup))

    # The parsing for lists requires an asterisk at the start
    # of the line, but some entries use bullets. This regex
    # swaps the bullets for asterisks.
    cell = bullets_re.sub("*", cell)

    # We don't want to have extra new lines added at the beginning or end
    # because that could make the wiki formatting odd
    cell = cell.strip()

    if cell.lower() == "null":
        cell = ""

    return cell

def split_sdg(cell, sdg_data):
    """Turns an sdg cell into a new line separated cell for us with torquedata.
    It uses SDG_DATA to split the array.  If it looks like the string doesn't
    have an entry, then an error is raised."""

    if sdg_data is None:
        raise Exception("Need SDG data")

    new_cell = ""
    cell = cell.strip()
    while cell is not "":
        found = False

        for sdg in [sdg_config["name"] for sdg_config in sdg_data]:
            if cell.startswith(sdg):
                found = True;
                new_cell += sdg + "\n"
                cell = cell[len(sdg):]
            if cell.startswith(","):
                cell = cell[1:]

        if not found:
            raise Exception("Could not find SDG in " + cell)

        cell = cell.strip();

    new_cell.strip()
    return new_cell

def create_column_types_row(header_row):
    """Declaration of the types different columns in the spreadsheet have,
    expressed as a row of strings that torque understands."""

    column_types = {
            "Attachments": "list",
            "Attachment Display Names": "list",
            "Sustainable Development Goals": "list",
            "Priority Populations": "list",
            }

    return [ (column_types[col] if col in column_types else "") for col in header_row ]

def print_csv(header_row, rows, output):
    """Print the HEADER_ROW and ROWS to OUTPUT via csv"""

    csv_writer = csv.writer(output,
                            delimiter=',', quotechar='"', lineterminator="\n")

    csv_writer.writerow(header_row)
    csv_writer.writerow(create_column_types_row(header_row))
    for row in rows:
        csv_writer.writerow(row)

def process_regionconfig_data(csv_reader):
    """Takes a CSV_READER representing a country ot region mapping in a
    spreadsheet and converts it into a dict representing a lookup by
    country.  If no reader is provided, then {} is returned.

    The return object, when CSV_READER is present is of the form:
      REGION_DATA_BY_COUNTRY[country] = {
        subregion: SUBREGION,
        region: REGION
      }
    """

    if csv_reader is None:
        return {}

    region_data_by_country = {}

    next(csv_reader)
    for row in csv_reader:
        region_data_by_country[row[0]] = { "subregion": row[1], "region": row[2] }

    return region_data_by_country

def process_sdgconfig_data(csv_reader):
    """Takes a CSV_READER representing a valid sdgs, and their number
    and converts it into a dict representing a lookup by sdg.
    If no reader is provided, then None is returned.

    The return object, when CSV_READER is present is of the form:
      SDG_DATA[name] = {
        number: integer
      }
    """

    if csv_reader is None:
        return None

    sdg_data = []

    next(csv_reader)
    for row in csv_reader:
        sdg_data.append({"name": row[1], 'number': row[0], })

    return sdg_data

def generate_generic_toc(toc_dir, grouped_review_numbers, toc_name):
    """Generates a TOC mwiki and TOC data file in TOC_DIR for the given data,
    which is a dict where the proposals are all grouped by some key.
    Then put into TOC_DIR/TOC_NAME.json.

    Notably, this doesn't create the jinja template file, as that doesn't
    need to be dynamically generated."""
    with open(os.path.join(toc_dir, toc_name + ".json"), 'w') as f:
        f.writelines(json.dumps({"groups": grouped_review_numbers}))

    with open(os.path.join(toc_dir, toc_name + ".mwiki"), 'w') as f:
        f.writelines(toc_name + "\n")
        f.writelines("{{ #tdcrender:proposals/toc/" + toc_name + ".mwiki }}")

def generate_sdg_toc(toc_dir, sdg_data, sdgconfig_data):
    """Generates a TOC mwiki and TOC data file in TOC_DIR for the given data,
    which is a dict where the proposals are all grouped by some key.
    Then put into TOC_DIR/TOC_NAME.json.

    Notably, this doesn't create the jinja template file, as that doesn't
    need to be dynamically generated."""
    grouped_data = []
    for sdgconfig in sdgconfig_data:
        grouped_data.append({
            'heading': sdgconfig['name'],
            'proposal_ids': sdg_data[sdgconfig['name']]
        })

    with open(os.path.join(toc_dir, "SDG_TOC.json"), 'w') as f:
        f.writelines(json.dumps({"sdgs": grouped_data}))

    with open(os.path.join(toc_dir, "SDG_TOC.mwiki"), 'w') as f:
        f.writelines("SDG_TOC\n")
        f.writelines("{{ #tdcrender:proposals/toc/SDG_TOC.mwiki }}")

def generate_geographic_toc(toc_dir, grouped_review_numbers):
    """Generates a special TOC page in TOC_DIR for the REGION_DATA, which is
    a dict where the proposals are all grouped by their region and subregion.

    Like GENERATE_GENERIC_TOC, this generates a mwiki for the page on the wiki,
    but not the template file."""

    with open(os.path.join(toc_dir, "/Geographic_TOC.json"), 'w') as f:
        f.writelines(json.dumps({"regions": grouped_review_numbers}))

    with open(os.path.join(toc_dir, "/Geographic_TOC.mwiki"), 'w') as f:
        f.writelines("Geographic_TOC" + "\n")
        f.writelines("{{ #tdcrender:proposals/toc/Geographic_TOC.mwiki }}")

valid_traits = [ "IMPACTFUL", "EVIDENCE-BASED", "FEASIBLE", "DURABLE" ]

def process_evaluation_data(*csv_reader, app_col, score_rank_col, sum_of_scores_col, trait_col,
        score_normalized_col, comments_col):
    """Takes a CSV_READER representing evaluation data in a spreadsheet and
    turns that into a dict of dicts in the following form:

      EVALUATION_DATA[app_id] = {
        overall_score_rank_normalized: string,
        sum_of_scores_normalized: string,
        traits: array of TRAIT (below)
      }

      TRAIT = {
        name: string,
        score_normalized: string
        comments: concatenated string
      }

    The columns that data is looked up are required named integer arguments as follows:
      - APP_COL: column with application number
      - SCORE_RANK_COL: column with normalized score rank
      - SUM_OF_SCORES_COL: column with normalized scores
      - TRAIL_COL: column with the trait name
      - SCORE_NORMALIZED_COL: column with the normalized score
      - COMMENTS_COL: column with the comments

    The evaluation data coming in has many comments in their own row to one
    application.  There are N traits, and M judges per trait, with things like
    overall_score_rank_normalized being duplicated for all NxM rows.

    The name of the trait has to be one of:
      - IMPACTFUL
      - EVIDENCE-BASED
      - FEASIBLE
      - DURABLE

    The reason we don't dynamically load this is that for the purposes of
    the json export, as well as the spreadsheet headers, we need to know
    the names of the traits.

    The scores for the traits are added up based here rather than in the
    spreasheet.  Then, comments are concatenated for that trait.
    """

    evaluation_data = {}

    next(csv_reader[0])
    for row in csv_reader[0]:
        application_id = row[app_col]
        if not application_id in evaluation_data:
            evaluation_data[application_id] = {
                    "overall_score_rank_normalized": row[score_rank_col],
                    "sum_of_scores_normalized": row[sum_of_scores_col],
                    "traits": [{ "name": trait, "score_normalized": 0, "comments": "" } for trait in valid_traits],
                    }

        judge_datum = evaluation_data[application_id]

        found = False

        if row[trait_col] not in valid_traits:
            raise Exception("Trait is not a valid trait: " + row[trait_col])

        for trait in judge_datum["traits"]:
            if trait["name"] == row[trait_col]:
                trait["score_normalized"] += float(row[score_normalized_col])
                trait["comments"] += "\n\n* " + row[comments_col]

    return evaluation_data

def process_ots_metadata(reader):
    """Process READER into a dictionary that's contextual based
    on what metadata ots needs to process the ETL pipeline.  This
    changes as special cases are brought up.  It returns an object
    where the attribute (column 1), maps to the value (column 2)
    for the given review number (column 0). The top level object is
    keyed on the review number.

    For instance:

    Review Number,Attribute,Value
    1,Wild Card,yes

    maps to

    { "1": { "Wild Card": "yes" } }
    """
    header = next(reader)

    metadata = {}
    for row in reader:
        review_number = row[0]
        attribute_name = row[1]
        value = row[2]

        if review_number not in metadata:
            metadata[review_number] = {}

        metadata[review_number][attribute_name] = value

    return metadata

def wiki_escape_page_title(s):
    import unidecode
    """Return a wiki-escaped version of STRING."""
    for c in ["#", "<", ">", "[", "]", "{", "|", "}",]:
        if s.find(c) != -1:
            s = s.replace(c, "-")
    while len(bytes(s, "UTF-8")) > 255:
        s = s[:-1]

    # Also convert non unicode because we do this with titles on the other side
    return unidecode.unidecode_expect_nonascii(s).strip()

def create_correction_data(correction_files):
    """Turns CORRECTION_FILES into a dictionary of dictionaries of the form:

    correction_data = {
      REVIEW_NUMBER_1 = {
        'CORRECTION_HEADER_1' = ...,
        'CORRECTION_HEADER_2' = ...,
        ...
      },
      REVIEW_NUMBER_1 = { ... },
      ...
    }"""

    correction_data = {}

    for correction_file in correction_files:
        correction_reader = csv.reader(open(correction_file, encoding='utf-8'),
                                       delimiter=',', quotechar='"')
        header = next(correction_reader)
        review_number_idx = header.index("Review Number")

        for correction_row in correction_reader:
            review_number = correction_row[review_number_idx]
            if review_number not in correction_data:
                correction_data[review_number] = {}
            for col_name, datum in zip(header, correction_row):
                correction_data[review_number][col_name] = datum

    return correction_data

def create_tdc_config(tdc_config_dir, header_row, new_rows):
    """Helper method to write out base config files to TDC_CONFIG_DIR.

    Needs HEADER_ROW and NEW_ROWS to generate the column and proposal
    data.  Generates the following:

      - AllProposals - All the proposals generated
      - Top100 - The top 100 proposals
      - Top100AndWildCards - the above but with the 113 declared wildcards
      - FinalistCandidates - the top 100, with wild cards, but omitting TR Disqualified
      - Top200 - The top 200 proposals
      - PassedReview - The ~455 proposals that passed wisehead review
      - AllColumns - All the available columns
      - ApiColumns - The columns used in v1 of the API
      - NonReviewColumns - The columns excepting ones relating to reviews
      """

    def row_to_title_line(row):
        return "* {3}: ".format(*row) + "[[" + row[206] + "]]\n"

    with open(os.path.join(tdc_config_dir, "AllProposals"), 'w') as f:
        f.writelines([row_to_title_line(row) for row in new_rows])

    with open(os.path.join(tdc_config_dir, "Top100"), 'w') as f:
        f.writelines([row_to_title_line(row) for row in new_rows if int(row[188]) < 101])

    with open(os.path.join(tdc_config_dir, "Top100AndWildcards"), 'w') as f:
        f.writelines([
            row_to_title_line(row)
            for row in new_rows
            if (int(row[188]) < 101 or row[207] == "Wild Card")])

    with open(os.path.join(tdc_config_dir, "FinalistCandidates"), 'w') as f:
        f.writelines([
            row_to_title_line(row)
            for row in new_rows
            if (int(row[188]) < 101 or row[207] == "Wild Card") and row[208] != "TR Disqualified" ])

    with open(os.path.join(tdc_config_dir, "Top200"), 'w') as f:
        # 202 here because there was a duplicate removed before
        f.writelines([row_to_title_line(row) for row in new_rows if int(row[188]) < 202])

    with open(os.path.join(tdc_config_dir, "PassedReview"), 'w') as f:
        f.writelines([row_to_title_line(row) for row in new_rows if int(row[188]) != 9999])

    with open(os.path.join(tdc_config_dir, "AllColumns"), 'w') as f:
        for column in header_row:
            f.writelines("* %s\n" % column)

    # These are hardcoded here, because where else?  We want this output
    # to go with the other tdc_config outputs, so here is the best place
    # to get into the project and update later.
    with open(os.path.join(tdc_config_dir, "ApiColumns"), 'w') as f:
        f.writelines([
             "* Organization Legal Name\n",
             "* City\n",
             "* State\n",
             "* Country\n",
             "* Principal Organization Website or Social Media\n",
             "* Identification Number of Principal Organization\n",
             "* Identification Number of Principal Organization ein\n",
             "* Primary Contact First Name\n",
             "* Primary Contact Last Name\n",
             "* Primary Contact Title\n",
             "* Primary Contact Email\n",
             "* Review Number\n",
             "* Project Title\n",
             "* Project Description\n",
             "* Executive Summary\n",
             "* Problem Statement\n",
             "* Solution Overview\n",
             "* Youtube Video\n",
             "* Location Of Future Work Country\n",
             "* Location Of Future Work2 Country\n",
             "* Location Of Future Work3 Country\n",
             "* Location Of Future Work4 Country\n",
             "* Location Of Future Work5 Country\n",
             "* Location Of Current Solution Country\n",
             "* Location Of Current Solution2 Country\n",
             "* Location Of Current Solution3 Country\n",
             "* Location Of Current Solution4 Country\n",
             "* Location Of Current Solution5 Country\n",
             "* Project Website or Social Media Page\n",
             "* Application Level\n",
             "* Competition Domain\n",
             ])

    review_columns = [
        "Judge Overall Score Rank Normalized",
        "Judge Sum of Scores Normalized",
        "Judge IMPACTFUL",
        "Judge IMPACTFUL Score Normalized",
        "Judge IMPACTFUL Comments",
        "Judge EVIDENCE-BASED",
        "Judge EVIDENCE-BASED Score Normalized",
        "Judge EVIDENCE-BASED Comments",
        "Judge FEASIBLE",
        "Judge FEASIBLE Score Normalized",
        "Judge FEASIBLE Comments",
        "Judge DURABLE",
        "Judge DURABLE Score Normalized",
        "Judge DURABLE Comments",
        "Wise Head Sum of Scores Normalized",
        "Wise Head IMPACTFUL",
        "Wise Head IMPACTFUL Score Normalized",
        "Wise Head IMPACTFUL Comments",
        "Wise Head EVIDENCE-BASED",
        "Wise Head EVIDENCE-BASED Score Normalized",
        "Wise Head EVIDENCE-BASED Comments",
        "Wise Head FEASIBLE",
        "Wise Head FEASIBLE Score Normalized",
        "Wise Head FEASIBLE Comments",
        "Wise Head DURABLE",
        "Wise Head DURABLE Score Normalized",
        "Wise Head DURABLE Comments",
    ]

    with open(os.path.join(tdc_config_dir, "NonReviewColumns"), 'w') as f:
        for column in header_row:
            if column not in review_columns:
                f.writelines("* %s\n" % column)

def compose_csvs(proposals, admin_review, judge_eval, wisehead_eval, ots_metadata_file, correction_files,
        regionconfig, sdgconfig, attachments_dir, toc_dir, tdc_config_dir, pare=None):
    """Write a composed version of PROPOSALS (a CSV file), ADMIN_REVIEW
    (a CSV file), and JUDGE_EVAL (a CSV file) to standard out.

    PROPOSALS, ADMIN_REVIEW, and JUDGE_EVAL are all filenames.  They
    represent a full list of proposals, a list of accepted proposals,
    and evaluation on those proposals, respectively

    CORRECTION_FILES is a list of files that contain data to overwrite the
    source data with blessed corrections.  Each one overwrites the previous
    if there are overlapping corrections.

    REGIONCONFIG is a filename of a simple mapping of countries to regions
    they belong to based on the UN geoscheme.  SDGCONFIG is a similar mapping
    for UN SDG codes.

    SDGCONFIG is a mapping for UN SDG codes.

    ATTACHMENTS_DIR is the directory to look in for attachments.

    TOC_DIR is the directory that, when not None, will have files written
    to it that are various tables of contents that are of interest to macfound.

    TDC_CONFIG_DIR is the directory that, when not None, will have files
    written to it that have the base configuration of columns, proposals, etc
    that we launched the LFC torque instance with.

    If PARE is not None, it is a positive integer indicating that only
    1 of every PARE entries should be processed, and the others skipped."""
    try:
        proposals_reader = csv.reader(open(proposals, encoding='utf-8'),
                                      delimiter=',', quotechar='"')
        admin_review_reader = csv.reader(open(admin_review, encoding='utf-8'),
                                         delimiter=',', quotechar='"')
        judge_eval_reader = csv.reader(open(judge_eval, encoding='utf-8'),
                                       delimiter=',', quotechar='"')
        wisehead_eval_reader = csv.reader(open(wisehead_eval, encoding='utf-8'),
                                       delimiter=',', quotechar='"')
        regionconfig_reader = csv.reader(open(regionconfig, encoding='utf-8'),
                                       delimiter=',', quotechar='"')
        sdgconfig_reader = csv.reader(open(sdgconfig, encoding='utf-8'),
                                       delimiter=',', quotechar='"')
        ots_metadata_reader = csv.reader(open(ots_metadata_file, encoding='utf-8'),
                                       delimiter=',', quotechar='"')
    except UnicodeDecodeError:
        sys.stderr.write("fix-csv expects utf-8-encoded unicode, not whatever is in this csv file.\n")
        sys.exit(-1)

    header_row = next(proposals_reader)
    for data_type in ["Judge", "Wise Head"]:
        header_row.append(data_type + " Overall Score Rank Normalized")
        header_row.append(data_type + " Sum of Scores Normalized")
        for trait in valid_traits:
            header_row.append(data_type + " " + trait)
            header_row.append(data_type + " " + trait + " Score Normalized")
            header_row.append(data_type + " " + trait + " Comments")
    header_row.append("Application Level")
    header_row.append("Attachment Display Names")
    header_row.append("Attachments")
    header_row.append("Wild Card Eligible")
    header_row.append("MediaWiki Title")
    header_row.append("Wild Card")
    header_row.append("TR Disqualified")

    # We only accept applications if they're one of the rows in the
    # admin_review csv, which has an "Application #" column (3),
    # which matches a "Review #" column in the proposals (3)
    # and for which the "Status" column (7) is valid
    next(admin_review_reader) # Don't look at header
    acceptable_application_numbers = { row[3]: row[7] for row in admin_review_reader }

    judge_data = process_evaluation_data(judge_eval_reader,
            app_col=3, score_rank_col=9, sum_of_scores_col=11,
            trait_col=15, score_normalized_col=13, comments_col=14)
    wisehead_data = process_evaluation_data(wisehead_eval_reader,
            app_col=3, score_rank_col=11, sum_of_scores_col=13,
            trait_col=19, score_normalized_col=17, comments_col=18)

    correction_data = create_correction_data(correction_files)
    sdgconfig_data = process_sdgconfig_data(sdgconfig_reader)
    ots_metadata = process_ots_metadata(ots_metadata_reader)
    attachments_to_upload = {}

    row_num = 0
    new_rows = []

    extra_cats = []
    for row in proposals_reader:
        if row[3] not in acceptable_application_numbers.keys():
            continue

        row_num += 1  # first row here is row 1 (the header row was row 0) 
        if pare is not None and row_num % pare != 0:
            continue

        if row[3] in wisehead_data:
            rank = int(wisehead_data[row[3]]["overall_score_rank_normalized"])
        else:
            # Marker value for invalid proposals that didn't get scored
            rank = 9999

        # This is required to be before the corrections because of legacy issues
        mwiki_title = wiki_escape_page_title("{30} ({3})".format(*row))

        if row[3] in correction_data:
            for col_header, correction_value in correction_data[row[3]].items():
                col_for_correction = header_row.index(col_header)
                row[col_for_correction] = correction_value

        new_row = []
        extra_output_row = []
        num_fixed_cells = 0
        for cell in row:
            fixed_cell = fix_cell(cell)
            if fixed_cell != cell:
                num_fixed_cells += 1
            new_row.append(fixed_cell)
            extra_output_row.append(fixed_cell)

        for evaluation_data in [judge_data, wisehead_data]:
            if row[3] in evaluation_data:
                new_row.extend([
                    evaluation_data[row[3]]["overall_score_rank_normalized"],
                    evaluation_data[row[3]]["sum_of_scores_normalized"] ])
    
                for valid_trait in valid_traits:
                    for trait in evaluation_data[row[3]]["traits"]:
                        if trait["name"] == valid_trait:
                            new_row.append(trait["name"])
                            new_row.append("{0:.1f}".format(trait["score_normalized"]))
                            new_row.append(trait["comments"])

            else:
                new_row.extend([9999, ""])
    
                # for now, we know that there are 4 traits
                for _ in range(4):
                    new_row.extend(["", "", ""])

        # Mutate the rows to add special wiki markup for categorization of pages.
        # This is special to the 2019 run.  We need to save the extra_categories
        # so that csv2wiki will make them
        #
        # We also collate all the data for tables of contents by category
        new_row[128] = split_sdg(row[128], sdgconfig_data)

        # Population
        new_row[58] = "\n".join(new_row[58].split(","))

        # This is application status.  Right now everything is NULL, but this will
        # get replaced as the process continues
        new_row.append("NULL")

        attachments_str = ""
        attachment_display_names = ""
        if attachments_dir is not None:
            attachments_to_upload[row[3]] = []
            application_attachment_dir = os.path.join(attachments_dir, row[3])
            for attachment_file in os.listdir(application_attachment_dir):
                if re.search("^\\d*_Registration.pdf", attachment_file):
                    continue

                attachment_display_name = re.sub("^\\d*_", "", attachment_file)
                attachment_display_name = re.sub("\.pdf$", "", attachment_display_name)
                if len(attachment_display_name) > 33:
                    attachment_display_name = \
                        attachment_display_name[0:15] + \
                        "..." + \
                        attachment_display_name[(len(attachment_display_name)-15):]

                attachments_str += attachment_file + "\n"
                attachment_display_names += attachment_display_name + "\n"
                attachments_to_upload[row[3]].append(attachment_file)
        new_row.append(attachment_display_names)
        new_row.append(attachments_str)

        if rank > 100 and rank <= 201:
            new_row.append("Wild Card Eligible")
        else:
            new_row.append("")

        new_row.append(mwiki_title)

        new_row.append(ots_metadata.get(row[3], {}).get("Wild Card", ""))
        new_row.append(ots_metadata.get(row[3], {}).get("TR Disqualified", ""))

        print("Sanitized row %d (rank %d, %d cols, %d fixed)." % (row_num, rank, len(new_row), num_fixed_cells), file=sys.stderr)
        new_rows.append(new_row)

    new_rows.sort(key=lambda row: int(row[188])) # Sort by wisehead rank

    # Build TOCs after sorted proposals

    if toc_dir is not None:
        # Population
        population_data = {}
        for new_row in new_rows:
            for population in new_row[58].split("\n"):
                if population not in population_data:
                    population_data[population] = []
                population_data[population].append(new_row[3])
        generate_generic_toc(toc_dir, population_data, "Population_TOC")

        # SDG
        sdg_data = {}
        for new_row in new_rows:
            for sdg in new_row[128].strip().split("\n"):
                if sdg not in sdg_data:
                    sdg_data[sdg] = []
                sdg_data[sdg].append(new_row[3])
        generate_sdg_toc(toc_dir, sdg_data, sdgconfig_data)

        # Topic
        topic_data = {}
        for new_row in new_rows:
            if new_row[66] not in topic_data:
                topic_data[new_row[66]] = []
            topic_data[new_row[66]].append(new_row[3])
        generate_generic_toc(toc_dir, topic_data, "Topic_TOC")

        # Geographic.  There's a "shown" flag for working with the template file
        # to know when to show headers, depending on whether proposals are valid.
        geographic_data = {}
        regionconfig_data_by_country = process_regionconfig_data(regionconfig_reader)
        country_errors = []
        for new_row in new_rows:
            for col in [68, 74, 80, 98, 104, 110, 116, 122]:
                try:
                    region = regionconfig_data_by_country[new_row[col]]["region"]
                    subregion = regionconfig_data_by_country[new_row[col]]["subregion"]
                    if region not in geographic_data:
                        geographic_data[region] = {"shown": False, "subregions": {}}
                    if subregion not in geographic_data[region]["subregions"]:
                        geographic_data[region]["subregions"][subregion] = {"shown": False, "countries": {}}
                    if new_row[col] not in geographic_data[region]["subregions"][subregion]["countries"]:
                        geographic_data[region]["subregions"][subregion]["countries"][new_row[col]] = {"shown": False, "proposals": []}
                    if new_row[3] not in geographic_data[region]["subregions"][subregion]["countries"][new_row[col]]["proposals"]:
                        geographic_data[region]["subregions"][subregion]["countries"][new_row[col]]["proposals"].append(new_row[3])
                except KeyError:
                    if new_row[col] not in country_errors:
                        print("Country %s not in region config file, skipping" % new_row[col], file=sys.stderr)
                        country_errors.append(new_row[col])
        generate_generic_toc(toc_dir, geographic_data, "Geographic_TOC")

    if attachments_dir is not None:
        with open(os.path.join(attachments_dir, "attachments_to_upload"), 'wb') as f:
            pickle.dump(attachments_to_upload, f)

    print_csv(header_row, new_rows, sys.stdout)

    if tdc_config_dir is not None:
        create_tdc_config(tdc_config_dir, header_row, new_rows)

def main():
    """Compose the MacFound input and emit it as html-ized csv."""
    try:
        opts, args = getopt.getopt(sys.argv[1:], '',
                                   ["pare=",
                                    "proposals-csv=",
                                    "admin-review-csv=",
                                    "judge-evaluation-csv=",
                                    "regionconfig-csv=",
                                    "wisehead-evaluation-csv=",
                                    "ots-metadata=",
                                    "sdgconfig-csv=",
                                    "toc-dir=",
                                    "tdc-config-dir=",
                                    "attachments-dir=",
                                    "correction-file=",])
    except getopt.GetoptError as err:
        sys.stderr.write("ERROR: '%s'\n" % err)
        sys.exit(2)

    pare = None
    proposals_csv = None
    admin_review_csv = None
    judge_evaluation_csv = None
    wisehead_evaluation_csv = None
    regionconfig_csv = None
    sdgconfig_csv = None
    attachments_dir = None
    toc_dir = None
    ots_metadata = None
    tdc_config_dir = None
    correction_files = []
    for o, a in opts:
        if o == "--pare":
            pare = int(a)
        elif o == "--proposals-csv":
            proposals_csv = a
        elif o == "--admin-review-csv":
            admin_review_csv = a
        elif o == "--judge-evaluation-csv":
            judge_evaluation_csv = a
        elif o == "--regionconfig-csv":
            regionconfig_csv = a
        elif o == "--wisehead-evaluation-csv":
            wisehead_evaluation_csv = a
        elif o == "--ots-metadata":
            ots_metadata = a
        elif o == "--sdgconfig-csv":
            sdgconfig_csv = a
        elif o == "--correction-file":
            correction_files.append(a)
        elif o == "--toc-dir":
            toc_dir = a
        elif o == "--tdc-config-dir":
            tdc_config_dir = a
        elif o == "--attachments-dir":
            attachments_dir = a
        else:
            sys.stderr.write("ERROR: unrecognized option '%s'\n" % o)
            sys.exit(2)

    if (proposals_csv is None or
            admin_review_csv is None or
            judge_evaluation_csv is None or
            wisehead_evaluation_csv is None):
        sys.stderr.write(
            "ERROR: need --proposals-csv, --admin-review-csv, " +
            "--judge-evaluation-csv, and --wisehead_evaluation-csv options.\n\n")
        sys.stderr.write(__doc__)
        sys.exit(1)
    compose_csvs(proposals_csv, admin_review_csv, judge_evaluation_csv, wisehead_evaluation_csv, ots_metadata,
            correction_files, regionconfig_csv, sdgconfig_csv, attachments_dir, toc_dir, tdc_config_dir, pare)

if __name__ == '__main__':
    main()
